# Ensemble-Classifier-and-Binary-Classification
In the past decade, numerous classification algorithms have been developed. 
One category of the classification algorithms that stand out among all algorithms 
is the ensemble classification. For this project, I am going to use random forest,
Adaboot, gradient boosting, bagging with k-nearest neighbor and bagging with 
decision tree to test on five different datasets: ADULT, ABALONE, BANK, IRIS, 
and OCCUPANCY. The goal is to compute the overall best ensemble classification 
method among the five algorithms and show that gradient boosting has an equally 
good performance as random forest.
Paper published to Intelligent Systems Conference (IntelliSys) 2019
